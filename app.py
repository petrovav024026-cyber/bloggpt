"""
FastAPI —Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º:
- Currents API (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç)
- OpenAI API (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
- –ü—Ä–µ—Å–µ—Ç—ã —Ü–µ–ª–µ–π (—Ç–æ–Ω, –∞—É–¥–∏—Ç–æ—Ä–∏—è, UTM, CTA-—Ä–æ—Ç–∞—Ü–∏—è)
- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –∑–¥–æ—Ä–æ–≤—å—è/–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏/–≤–µ—Ä—Å–∏–∏/–ø—Ä–µ—Å–µ—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ CORS
- –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ uvicorn

–ê–≤—Ç–æ—Ä: –≤—ã :)
–î–∞—Ç–∞: 2025-08-09
"""

from __future__ import annotations

import os
import re
import math
import json
import random
import logging
from typing import List, Optional, Dict, Any, Literal
from dataclasses import dataclass

import requests
from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, HttpUrl

# --------------------------- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï -------------------------------------
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=LOG_LEVEL,
    format="%(asctime)s %(levelname)s %(name)s :: %(message)s",
)
logger = logging.getLogger("content-suite")

# ------------------------------ OpenAI ---------------------------------------
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç openai. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai") from e

# ----------------------------- tiktoken --------------------------------------
try:
    import tiktoken
    HAS_TIKTOKEN = True
except Exception:
    HAS_TIKTOKEN = False

# =============================================================================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –ø—Ä–µ—Å–µ—Ç—ã
# =============================================================================

# –ö–ª—é—á–∏ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CURRENTS_API_KEY = os.getenv("CURRENTS_API_KEY")

if not OPENAI_API_KEY:
    logger.warning("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω! /ready –ø–æ–∫–∞–∂–µ—Ç not_ready.")
if not CURRENTS_API_KEY:
    logger.warning("CURRENTS_API_KEY –Ω–µ –∑–∞–¥–∞–Ω! –ù–æ–≤–æ—Å—Ç–∏ Currents –Ω–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã.")

# –ú–æ–¥–µ–ª–∏
DEFAULT_TEXT_MODEL = os.getenv("OPENAI_TEXT_MODEL", "gpt-4o-mini")
DEFAULT_IMAGE_MODEL = os.getenv("OPENAI_IMAGE_MODEL", "gpt-image-1")

# –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã (–æ–±–Ω–æ–≤–∏—Ç–µ –ø–æ–¥ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ)
PRICING_PER_1K = {
    "gpt-4o-mini": {"input": 0.15, "output": 0.60},
    "gpt-4o": {"input": 5.00, "output": 15.00},
}

# –ü—Ä–µ—Å–µ—Ç—ã
TONE_PRESETS: Dict[str, str] = {
    "friendly_expert": "–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –±–µ–∑ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞",
    "witty_brisk": "–æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –±—ã—Å—Ç—Ä—ã–π, –±–µ–∑ –≤–æ–¥—ã, —Å –ª—ë–≥–∫–∏–º–∏ —à—É—Ç–∫–∞–º–∏",
    "serious_trust": "–¥–µ–ª–æ–≤–æ–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π, –¥–∞—ë—Ç —è—Å–Ω—ã–µ –≤—ã–≤–æ–¥—ã",
    "ironic_smart": "–∏—Ä–æ–Ω–∏—á–Ω—ã–π, —É–º–Ω—ã–π, —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π, –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏",
}

AUDIENCE_PRESETS: Dict[str, str] = {
    "tg_productivity": "–ø–æ–¥–ø–∏—Å—á–∏–∫–∏ Telegram-–∫–∞–Ω–∞–ª–∞ –æ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–∏",
    "smm_founders": "–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª–∏ –∏ SMM-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞",
    "devs_ai": "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∏ —ç–Ω—Ç—É–∑–∏–∞—Å—Ç—ã –ò–ò-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
    "realty_leads": "–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏ –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤ –∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å",
}

THEME_PRESETS: Dict[str, Dict[str, Any]] = {
    "leads": {
        "keywords": ["–∞–∫—Ü–∏—è", "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è", "–∑–∞—è–≤–∫–∞", "—Å–∫–∏–¥–∫–∞"],
        "base_url": "https://example.com/offer",
        "utm": {"source": "telegram", "medium": "social", "campaign": "leads_tg", "content": "{slug}"},
    },
    "traffic": {
        "keywords": ["–≥–∞–π–¥", "—á–µ–∫-–ª–∏—Å—Ç", "–ø–æ–¥–±–æ—Ä–∫–∞", "–±–ª–æ–≥"],
        "base_url": "https://example.com/blog",
        "utm": {"source": "telegram", "medium": "social", "campaign": "blog_push", "content": "{slug}"},
    },
    "ironic": {
        "keywords": ["–∏—Ä–æ–Ω–∏—è", "—Ö–æ–ª–æ–¥–Ω—ã–µ —Ñ–∞–∫—Ç—ã", "—é–º–æ—Ä"],
        "base_url": "https://example.com/post",
        "utm": {"source": "telegram", "medium": "social", "campaign": "brand_tone", "content": "{slug}"},
    },
}

# –¶–µ–ª–∏ —Å UTM –∏ —Ä–æ—Ç–∞—Ü–∏–µ–π CTA
GOAL_PRESETS: Dict[str, Dict[str, Any]] = {
    "leads": {
        "tone": "serious_trust",
        "audience": "realty_leads",
        "theme": "leads",
        "utm": {
            "base_url": "https://example.com/offer",
            "source": "telegram",
            "medium": "social",
            "campaign": "leadgen_q3",
            "content": "{slug}",
        },
        "cta_variants": [
            "–û—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É ‚Äî –ø–æ–¥—Å–∫–∞–∂–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç üöÄ",
            "–ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –æ—Ç–≤–µ—Ç–∏–º –≤ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞ ‚úâÔ∏è",
            "–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è ‚Äî –±—Ä–æ–Ω–∏—Ä—É–π—Ç–µ —Å–ª–æ—Ç üìÖ",
        ],
    },
    "traffic": {
        "tone": "witty_brisk",
        "audience": "tg_productivity",
        "theme": "traffic",
        "utm": {
            "base_url": "https://example.com/blog",
            "source": "telegram",
            "medium": "social",
            "campaign": "blog_push",
            "content": "{slug}",
        },
        "cta_variants": [
            "–ß–∏—Ç–∞–π—Ç–µ –ø–æ–ª–Ω—ã–π –≥–∞–π–¥ –ø–æ —Å—Å—ã–ª–∫–µ üìö",
            "–£ –Ω–∞—Å –ø–æ–¥–±–æ—Ä–∫–∞ ‚Äî –∑–∞–≥–ª—è–Ω–∏—Ç–µ üëÄ",
            "–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏, –∂–º–∏—Ç–µ ‚Üó",
        ],
    },
    "brand": {
        "tone": "friendly_expert",
        "audience": "smm_founders",
        "theme": "ironic",
        "utm": {
            "base_url": "https://example.com/brand",
            "source": "telegram",
            "medium": "social",
            "campaign": "brand_awareness",
            "content": "{slug}",
        },
        "cta_variants": [
            "–ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤–æ–µ ‚ú®",
            "–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ø–æ—Å—Ç ‚Äî –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è üìå",
            "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –∫–æ–ª–ª–µ–≥–∞–º ‚Äî –ø—É—Å—Ç—å —Ç–æ–∂–µ –∑–Ω–∞—é—Ç ü§ù",
        ],
    },
    "offer": {
        "tone": "serious_trust",
        "audience": "realty_leads",
        "theme": "leads",
        "utm": {
            "base_url": "https://example.com/offer",
            "source": "telegram",
            "medium": "social",
            "campaign": "special_offer",
            "content": "{slug}",
        },
        "cta_variants": [
            "–ó–∞–±—Ä–æ–Ω–∏—Ä—É–π—Ç–µ –ø–æ –∞–∫—Ü–∏–∏ ‚Äî –º–µ—Å—Ç –Ω–µ–º–Ω–æ–≥–æ üéØ",
            "–£—Å–ø–µ–π—Ç–µ —Å–µ–≥–æ–¥–Ω—è ‚Äî –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ ‚è≥",
            "–£—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏ ‚Äî —Å–¥–µ–ª–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç üìà",
        ],
    },
    "news": {
        "tone": "friendly_expert",
        "audience": "devs_ai",
        "theme": "traffic",
        "utm": {
            "base_url": "https://example.com/news",
            "source": "telegram",
            "medium": "social",
            "campaign": "news_update",
            "content": "{slug}",
        },
        "cta_variants": [
            "–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ ‚Üó",
            "–ß–∏—Ç–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –±–ª–æ–≥–µ üì∞",
            "–°–æ–±—Ä–∞–ª–∏ —Ñ–∞–∫—Ç—ã –∏ –ø—Ä–∏–º–µ—Ä—ã ‚Äî –∑–∞—Ö–æ–¥–∏—Ç–µ üëÄ",
        ],
    },
    "expert_tip": {
        "tone": "friendly_expert",
        "audience": "tg_productivity",
        "theme": "traffic",
        "utm": {
            "base_url": "https://example.com/tips",
            "source": "telegram",
            "medium": "social",
            "campaign": "expert_tips",
            "content": "{slug}",
        },
        "cta_variants": [
            "–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —á–µ–∫-–ª–∏—Å—Ç ‚Äî –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è üìå",
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ–ª–ª–µ–≥–µ ‚Äî –ø—É—Å—Ç—å —Ç–æ–∂–µ —É—Å–∫–æ—Ä–∏—Ç—Å—è ‚ö°",
            "–ï—â—ë –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ‚Äî –ø–æ —Å—Å—ã–ª–∫–µ ‚Üó",
        ],
    },
}

# =============================================================================
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
# =============================================================================

def estimate_tokens(text: str, model: str = DEFAULT_TEXT_MODEL) -> int:
    """–¢–æ—á–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç —á–µ—Ä–µ–∑ tiktoken (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ~4 —Å–∏–º–≤–æ–ª–∞/—Ç–æ–∫–µ–Ω."""
    if HAS_TIKTOKEN:
        try:
            enc = tiktoken.encoding_for_model(model)
        except Exception:
            enc = tiktoken.get_encoding("cl100k_base")
        return len(enc.encode(text or ""))
    return max(1, math.ceil(len(text or "") / 4))


def estimate_cost(input_tokens: int, output_tokens: int, model: str = DEFAULT_TEXT_MODEL) -> float:
    price = PRICING_PER_1K.get(model) or {"input": 0.0, "output": 0.0}
    return (input_tokens / 1000) * price["input"] + (output_tokens / 1000) * price["output"]


def slugify(text: str, max_len: int = 80) -> str:
    """–£–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Å–ª–∞–≥: –ª–∞—Ç–∏–Ω–∏—Ü–∞/—Ü–∏—Ñ—Ä—ã/–¥–µ—Ñ–∏—Å—ã, –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, –æ–±—Ä–µ–∑–∫–∞."""
    import unicodedata
    text = unicodedata.normalize("NFKD", text or "").lower()
    text = re.sub(r"[—ë]", "e", text)
    text = re.sub(r"[^a-z0-9\-\_\s]+", "", text)
    text = re.sub(r"[\s_]+", "-", text).strip("-")
    return text[:max_len] or "post"


def build_utm(url: str, source="telegram", medium="social", campaign="content", content: Optional[str] = None) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç UTM-—Å—Å—ã–ª–∫—É –ø–æ–≤–µ—Ä—Ö –ª—é–±–æ–≥–æ –±–∞–∑–æ–≤–æ–≥–æ URL."""
    from urllib.parse import urlencode, urlsplit, urlunsplit, parse_qsl
    parts = list(urlsplit(url))
    q = dict(parse_qsl(parts[3]))
    q.update({"utm_source": source, "utm_medium": medium, "utm_campaign": campaign})
    if content:
        q["utm_content"] = content
    parts[3] = urlencode(q, doseq=True)
    return urlunsplit(parts)


def resolve_preset(value: Optional[str], presets: Dict[str, str], default: Optional[str]) -> str:
    """–ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –∫–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞ ‚Äî –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç, –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ/–¥–µ—Ñ–æ–ª—Ç."""
    if not value and default:
        return default
    if value in presets:
        return presets[value]
    return value or (default or "")

# =============================================================================
# Pydantic –º–æ–¥–µ–ª–∏ –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤
# =============================================================================

class GenerateRequest(BaseModel):
    topic: str = Field(..., description="–¢–µ–º–∞ –ø–æ—Å—Ç–∞")
    goal: Optional[Literal["leads", "traffic", "brand", "offer", "news", "expert_tip"]] = Field(
        default=None, description="–¶–µ–ª—å –ø–æ—Å—Ç–∞: –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–Ω/–¶–ê/—Ç–µ–º—É/UTM/CTA-—Ä–æ—Ç–∞—Ü–∏—é"
    )
    tone: Optional[str] = Field(default=None, description="–¢–æ–Ω (–∫–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç)")
    audience: Optional[str] = Field(default=None, description="–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è (–∫–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç)")
    theme: Optional[Literal["leads", "traffic", "ironic"]] = Field(
        default=None, description="–¢–µ–º–∞—Ç–∏–∫–∞ (–¥–æ–±–∞–≤–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –∑–∞–ø–∞—Å–Ω—ã–µ UTM)"
    )
    length: Literal["short", "medium", "long"] = Field(default="medium", description="–î–ª–∏–Ω–∞ –ø–æ—Å—Ç–∞")
    language: str = Field(default="ru", description="–Ø–∑—ã–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (ru/en/...)")
    keywords: Optional[List[str]] = Field(default=None, description="–î–æ–ø. –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞")
    news_limit: int = Field(default=3, ge=0, le=10, description="–°–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π Currents –ø–æ–¥—Ç—è–Ω—É—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç")
    news_language: Optional[str] = Field(default=None, description="–Ø–∑—ã–∫ –Ω–æ–≤–æ—Å—Ç–µ–π Currents (ru/en/...)")
    temperature: float = Field(default=0.7, ge=0.0, le=2.0, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    make_image: bool = Field(default=False, description="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ª–∏ –æ–±–ª–æ–∂–∫—É —á–µ—Ä–µ–∑ OpenAI Images")


class NewsItem(BaseModel):
    title: str
    description: Optional[str] = None
    url: Optional[HttpUrl] = None
    author: Optional[str] = None
    published: Optional[str] = None


class GenerateResponse(BaseModel):
    title: str
    meta_description: str
    post: str
    hashtags: List[str]
    cta: str
    image_prompt: str
    image_url: Optional[HttpUrl] = None
    slug: str
    utm_link: Optional[HttpUrl] = None
    input_tokens: int
    output_tokens: int
    cost_estimate: float
    news_used: List[NewsItem] = Field(default_factory=list)

# =============================================================================
# Currents API ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π
# =============================================================================

def fetch_news_from_currents(
    query: str,
    api_key: Optional[str],
    language: Optional[str] = None,
    limit: int = 3,
    timeout_sec: int = 20,
) -> List[NewsItem]:
    """
    –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ Currents API.
    –ï—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫,
    —á—Ç–æ–±—ã —Å–µ—Ä–≤–∏—Å –ø—Ä–æ–¥–æ–ª–∂–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å.
    """
    if not api_key or limit <= 0:
        return []

    url = "https://api.currentsapi.services/v1/search"
    params = {
        "keywords": query,
        "apiKey": api_key,
        "limit": max(1, min(limit, 50)),
    }
    if language:
        params["language"] = language

    try:
        resp = requests.get(url, params=params, timeout=timeout_sec)
        if resp.status_code != 200:
            logger.warning("Currents API non-200: %s %s", resp.status_code, resp.text[:300])
            return []
        data = resp.json()
    except Exception as e:
        logger.warning("Currents API error: %s", e)
        return []

    items: List[NewsItem] = []
    news = (data or {}).get("news") or (data or {}).get("articles") or []
    for n in news[:limit]:
        items.append(
            NewsItem(
                title=str(n.get("title", "")).strip(),
                description=(n.get("description") or n.get("summary") or "")[:600],
                url=n.get("url"),
                author=n.get("author"),
                published=n.get("published") or n.get("publishedAt"),
            )
        )
    return items

# =============================================================================
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI (—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π)
# =============================================================================

@dataclass
class PostSpec:
    title: str
    meta_description: str
    post: str
    hashtags: List[str]
    cta: str
    image_prompt: str
    input_tokens: int = 0
    output_tokens: int = 0
    cost_estimate: float = 0.0


def make_news_context(news: List[NewsItem]) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–¥—Å–∫–∞–∑–∫–∏ –º–æ–¥–µ–ª–∏ (–Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)."""
    if not news:
        return "–ù–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, –∫–æ–Ω—Ç–µ–Ω—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–µ–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
    lines = ["–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ (–∫—Ä–∞—Ç–∫–æ):"]
    for i, n in enumerate(news, 1):
        line = f"{i}) {n.title}"
        if n.description:
            line += f" ‚Äî {n.description}"
        if n.url:
            line += f" ({n.url})"
        lines.append(line)
    return "\n".join(lines[:12])


def call_openai_structured(
    client: OpenAI,
    model: str,
    topic: str,
    tone: str,
    audience: str,
    length: str,
    language: str,
    keywords: List[str],
    cta_hint: str,
    news_context: str,
    temperature: float = 0.7,
) -> PostSpec:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç OpenAI Chat Completions –∏ –ø—Ä–æ—Å–∏—Ç –≤–µ—Ä–Ω—É—Ç—å JSON —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏.
    –í–∫–ª—é—á–∞–µ–º –≤ prompt –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π (news_context).
    """
    system_prompt = f"–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π SMM-—Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, —á—ë—Ç–∫–æ –∏ –±–µ–∑ –≤–æ–¥—ã, –Ω–∞ —è–∑—ã–∫–µ: {language}."

    user_prompt = f"""
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç –¥–ª—è Telegram.

–¢–µ–º–∞: {topic}
–¢–æ–Ω: {tone}
–ê—É–¥–∏—Ç–æ—Ä–∏—è: {audience}
–î–ª–∏–Ω–∞: {length}
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords) if keywords else '‚Äî'}
CTA (–æ—Ä–∏–µ–Ω—Ç–∏—Ä, –º–æ–∂–Ω–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –±–ª–∏–∑–∫–æ –∫ —Å–º—ã—Å–ª—É): {cta_hint or '‚Äî'}

{news_context}

–í–µ—Ä–Ω–∏ JSON c –ø–æ–ª—è–º–∏:
- title
- meta_description
- post
- hashtags (–º–∞—Å—Å–∏–≤ 5‚Äì10, –±–µ–∑ # –≤–Ω—É—Ç—Ä–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
- cta
- image_prompt

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ó–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ –∫–∞–≤—ã—á–µ–∫
- –•—ç—à—Ç–µ–≥–∏ ‚Äî –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏
- –ë–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ø—Ä–µ–∞–º–±—É–ª—ã: —Ç–æ–ª—å–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON
""".strip()

    input_tokens = estimate_tokens(system_prompt + "\n" + user_prompt, model=model)

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=temperature,
            max_tokens=900,
        )
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"OpenAI error: {e}")

    content = (resp.choices[0].message.content or "").strip()

    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç–∞
    try:
        payload = json.loads(content)
    except Exception:
        start = content.find("{")
        end = content.rfind("}")
        if start >= 0 and end > start:
            try:
                payload = json.loads(content[start : end + 1])
            except Exception:
                raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON-–æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏.")
        else:
            raise HTTPException(status_code=500, detail="–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–Ω–µ JSON).")

    title = str(payload.get("title", "")).strip()
    meta_description = str(payload.get("meta_description", "")).strip()
    post = str(payload.get("post", "")).strip()
    hashtags = payload.get("hashtags", [])
    if not isinstance(hashtags, list):
        hashtags = []
    hashtags = [str(x).lstrip("#").strip() for x in hashtags][:10]
    cta_out = str(payload.get("cta", "")).strip()
    image_prompt = str(payload.get("image_prompt", "")).strip()

    output_tokens = estimate_tokens(content, model=model)
    cost_est = estimate_cost(input_tokens, output_tokens, model=model)

    return PostSpec(
        title=title,
        meta_description=meta_description,
        post=post,
        hashtags=hashtags,
        cta=cta_out,
        image_prompt=image_prompt,
        input_tokens=input_tokens,
        output_tokens=output_tokens,
        cost_estimate=round(cost_est, 6),
    )


def generate_image_url(client: OpenAI, prompt: str, size: str = "1024x1024", model: str = DEFAULT_IMAGE_MODEL) -> Optional[str]:
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É OpenAI Images —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–±–µ–∑ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/—Ö—Ä–∞–Ω–µ–Ω–∏—è)."""
    if not prompt:
        return None
    try:
        img = client.images.generate(model=model, prompt=prompt, size=size, n=1)
        # –í –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö SDK –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–¥–∞–µ—Ç—Å—è b64_json; –µ—Å–ª–∏ –µ—Å—Ç—å url, –≤–µ—Ä–Ω–µ–º –µ–≥–æ
        if getattr(img.data[0], "url", None):
            return img.data[0].url
        if getattr(img.data[0], "b64_json", None):
            # –ï—Å–ª–∏ –ø—Ä–∏—à–ª–∞ base64-–∫–∞—Ä—Ç–∏–Ω–∫–∞, –æ—Å—Ç–∞–≤–∏–º —Å—Å—ã–ª–∫—É –ø—É—Å—Ç–æ–π, —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç —Ä–µ—à–∏–ª, —á—Ç–æ –¥–µ–ª–∞—Ç—å
            return None
        return None
    except Exception as e:
        logger.warning("Image generation failed: %s", e)
        return None

# =============================================================================
# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
# =============================================================================

app = FastAPI(
    title="Content Suite API (FastAPI)",
    version="1.0.0",
    description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π (Currents) –∏ OpenAI.",
)
from fastapi.responses import FileResponse, HTMLResponse
import os

@app.get("/", include_in_schema=False)
def ui():
    """–û—Ç–¥–∞—ë—Ç index.html –∏–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."""
    if os.path.exists("index.html"):
        return FileResponse("index.html")
    return HTMLResponse("<p>index.html not found. Endpoints: /health, /ready, /generate, /docs</p>")

# CORS (—É–¥–æ–±–Ω–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏/—Ñ—Ä–æ–Ω—Ç–∞)
origins_env = os.getenv("CORS_ALLOW_ORIGINS", "*")
origins = [o.strip() for o in origins_env.split(",")] if origins_env else ["*"]
allow_credentials_flag = False if origins == ["*"] else True

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=allow_credentials_flag,
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_openai_client() -> OpenAI:
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI (—á—Ç–æ–±—ã /ready –º–æ–≥ –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–∞)."""
    if not OPENAI_API_KEY:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω.")
    return OpenAI(api_key=OPENAI_API_KEY)

# --------------------- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ -------------------------------

@app.get("/health", tags=["meta"])
def health() -> Dict[str, str]:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–∏–Ω–≥: —Å–µ—Ä–≤–∏—Å –∂–∏–≤."""
    return {"status": "ok"}

@app.get("/ready", tags=["meta"])
def ready() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π –∏ –±–∞–∑–æ–≤—É—é –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Ä–∞–±–æ—Ç–µ."""
    return {
        "openai": bool(OPENAI_API_KEY),
        "currents": bool(CURRENTS_API_KEY),
        "text_model": DEFAULT_TEXT_MODEL,
        "image_model": DEFAULT_IMAGE_MODEL,
        "status": "ready" if OPENAI_API_KEY else "not_ready",
    }

@app.get("/version", tags=["meta"])
def version() -> Dict[str, str]:
    return {"version": app.version}

@app.get("/presets/goals", tags=["presets"])
def get_goal_presets() -> Dict[str, Any]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–µ–ª–∏ –∏ –∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–ª—è —Ñ—Ä–æ–Ω—Ç–æ–≤/–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤)."""
    out = {}
    for k, v in GOAL_PRESETS.items():
        out[k] = {
            "tone": v["tone"],
            "audience": v["audience"],
            "theme": v["theme"],
            "utm": v["utm"],
            "cta_variants": v["cta_variants"],
        }
    return out

# --------------------------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è --------------------------------------

@app.post("/generate", response_model=GenerateResponse, tags=["generate"])
def generate(req: GenerateRequest = Body(...)) -> GenerateResponse:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω:
    1) –¢—è–Ω–µ–º –Ω–æ–≤–æ—Å—Ç–∏ Currents –ø–æ —Ç–µ–º–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á)
    2) –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–µ–ª—å-–ø—Ä–µ—Å–µ—Ç: —Ç–æ–Ω/–¶–ê/—Ç–µ–º–∞/UTM/CTA-—Ä–æ—Ç–∞—Ü–∏—è
    3) –°–æ–±–∏—Ä–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É —Å –Ω–æ–≤–æ—Å—Ç–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –≤—ã–∑—ã–≤–∞–µ–º OpenAI
    4) –§–æ—Ä–º–∏—Ä—É–µ–º slug, UTM-—Å—Å—ã–ª–∫—É; –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º image_url
    """
    client = get_openai_client()

    # –ù–æ–≤–æ—Å—Ç–∏ Currents
    news_items = fetch_news_from_currents(
        query=req.topic,
        api_key=CURRENTS_API_KEY,
        language=req.news_language,
        limit=req.news_limit,
    )
    news_context = make_news_context(news_items)

    # –ü—Ä–µ—Å–µ—Ç—ã –ø–æ —Ü–µ–ª–∏
    tone_in = req.tone
    audience_in = req.audience
    theme_in = req.theme
    cta_hint = ""
    utm_link: Optional[str] = None

    if req.goal and req.goal in GOAL_PRESETS:
        gp = GOAL_PRESETS[req.goal]
        tone_in = tone_in or gp["tone"]
        audience_in = audience_in or gp["audience"]
        theme_in = theme_in or gp["theme"]
        cta_hint = random.choice(gp.get("cta_variants", [])) if gp.get("cta_variants") else ""

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–º—ã
    keywords = list(req.keywords or [])
    if theme_in and theme_in in THEME_PRESETS:
        for kw in THEME_PRESETS[theme_in].get("keywords", []):
            if kw not in keywords:
                keywords.append(kw)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è OpenAI
    spec = call_openai_structured(
        client=client,
        model=DEFAULT_TEXT_MODEL,
        topic=req.topic,
        tone=resolve_preset(tone_in, TONE_PRESETS, tone_in),
        audience=resolve_preset(audience_in, AUDIENCE_PRESETS, audience_in),
        length=req.length,
        language=req.language,
        keywords=keywords,
        cta_hint=cta_hint,
        news_context=news_context,
        temperature=req.temperature,
    )

    # –°–ª–∞–≥
    s = slugify(spec.title or req.topic)

    # UTM: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ —Ü–µ–ª–∏, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –∏–∑ —Ç–µ–º—ã (–∑–∞–ø–∞—Å–Ω–æ–π)
    if req.goal and req.goal in GOAL_PRESETS and GOAL_PRESETS[req.goal].get("utm"):
        u = GOAL_PRESETS[req.goal]["utm"]
        utm_link = build_utm(
            u["base_url"],
            source=u.get("source", "telegram"),
            medium=u.get("medium", "social"),
            campaign=u.get("campaign", "content"),
            content=(u.get("content", "{slug}") or "{slug}").format(slug=s),
        )
    elif theme_in and theme_in in THEME_PRESETS:
        utm_cfg = THEME_PRESETS[theme_in].get("utm", {})
        base = THEME_PRESETS[theme_in]["base_url"]
        utm_link = build_utm(
            base,
            source=utm_cfg.get("source", "telegram"),
            medium=utm_cfg.get("medium", "social"),
            campaign=utm_cfg.get("campaign", "content"),
            content=(utm_cfg.get("content", "{slug}") or "{slug}").format(slug=s),
        )

    # –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π CTA-–≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ –±—ã–ª
    if cta_hint:
        spec.cta = cta_hint

    # –ö–∞—Ä—Ç–∏–Ω–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    image_url = None
    if req.make_image:
        image_url = generate_image_url(client, prompt=spec.image_prompt)

    return GenerateResponse(
        title=spec.title,
        meta_description=spec.meta_description,
        post=spec.post,
        hashtags=spec.hashtags,
        cta=spec.cta,
        image_prompt=spec.image_prompt,
        image_url=image_url,
        slug=s,
        utm_link=utm_link,
        input_tokens=spec.input_tokens,
        output_tokens=spec.output_tokens,
        cost_estimate=spec.cost_estimate,
        news_used=news_items,
    )

# ----------------------- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—à–∏–±–æ–∫ -----------------------

@app.exception_handler(HTTPException)
def http_exc_handler(_, exc: HTTPException):
    return JSONResponse(status_code=exc.status_code, content={"detail": exc.detail})

@app.exception_handler(Exception)
def generic_exc_handler(_, exc: Exception):
    logger.exception("Unhandled exception: %s", exc)
    return JSONResponse(status_code=500, content={"detail": "Internal Server Error"})

# ----------------------------- –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ uvicorn --------------------------

if __name__ == "__main__":
    import uvicorn
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    reload_flag = os.getenv("RELOAD", "false").lower() in ("1", "true", "yes")
    uvicorn.run("app:app", host=host, port=port, reload=reload_flag)
